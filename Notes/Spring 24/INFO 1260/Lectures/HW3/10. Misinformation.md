- Platforms are influenced by a number of different practical considerations in deciding what moderation policies to implement and how
	- Who, when. how to think about political and cultural variation, how to think about changing language and how much to rely on automation
### Misinformation
- Often associated with hate and harassment
	- Content moderation concern with both
- Contribution to filter bubbles / polarization
- Exploitation of personalization and ranks and attention metrics for amplification of false or misleading messaging -> information disorder
- Who creates misinformation
	- Government, partisans, organizations, trolls
		- Some intentional some not
	- Motivations: Political, financial, ideological, psychological

- Personalization, speed, scale, attention dynamics change the nature of online speech and complicate the problem
### How to Decide what Info Sources to Consume
- Pre internet
	- Structured, coarse, logistically and geographically limited
	- Consumption choices made well before consumption
- Now
	- Immediate, lack of structural limitation on source selection; fine grained
	- No  pre commitment to a source
	- Shorter term thinking about what to consume
	- Driven by social endorsement and personalization
- Sunstein: Common experiences can lead to social solidarity
- Not about the greater availability of news sources; structural and behavioral dynamics that come with
- Epistemic Goal: Want more people to believe the truth
	- Empirically, people with access to the same information can develop divergent beliefs depending on motivation and prior views
### Familiarity Problem
- Metacognitive experience of becoming more familiar with a claim tends to belief in the claim; this matters more than the truth value of the claim
- Flu experiment Schwarz
	- Show people the flu facts and myths flyer, facts or nothing
### Misinformation Does not have to be Convincing
- Snakes
- Presence of misleading information increases the probability of false positives
- Subtle misinformation
	- Misleading content
	- Just joking but maybe not
	- Layered messages, innuendo, dog whistles
	- Edited content
		- Deep fake: Synthetic images depicting someone doing something they did not do
		- Shallow fake: No deep learning just video editing 
- Questionable authenticity of some information undermines trust in all information
- Doubt truth
	- Spread misinformation
	- Denounce accurate information as misinformation
- Emphasis on critical consumption and authenticity infrastructure
- Harm of misinformation extends beyond any one instance
### Make Misinformation Illegal
- Some countries have but human rights group oppose
- Difficult line drawing problems
- Chilling effect
- Misinformation is protected by First Amendment
- Section 230 blocks platform liability
- ![[Pasted image 20240222013753.png]]
- Platforms weigh immediate vs long term objectives
- Platforms business model (driving attentions via clicks incentivize giving spotlight to sensational content)
- Consider long term consequences of too much misinformation
- Rules against manipulated media
- Scores assigned to publishers promote and demote on this basis
	- Temporarily give more weight around election now rolled back
### Content Neutral Policies
- Can make it harder to fact check claims but limit spread of misinformation
- Forwarding limits: Any WhatsApp message that has been forwarded >=5 can be forwarded to 1 contact at a time
	- 70% reduction of highly forwarded messages
- Time place and manner restrictions
### Well intention efforts can Backfire
- Oxygen problem: Going out of ones way to debunk falsehoods can give more oxygen to them and increase lifespan
- Reporting on existence of misinformation can motivate misinformation actors and amplify falsehood subtle differences in framing can have different effects
### Soft Interventions
- Remedy for bad speech is more speech
- Implied Truth Effect: Labeling some stories as false makes people trust unlabeled stories more