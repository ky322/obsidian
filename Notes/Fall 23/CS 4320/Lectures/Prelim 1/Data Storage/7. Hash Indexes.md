### Hash VS Tree Indexes
- Tree Index: Traverse search tree to find interesting leaves
- Hash Index: Evaluate hash function to find buckets
### Supported Predicates
- Tree indexes
	- Tree indexes are based on a sort order between keys
		- Can handle equality and inequality conditions
			- Consecutive keys are stored close together
		- Composite keys: Useful for conditions on key prefix
			- Keys with same prefix values stored close together
- Hash Indexes
	- Hash indexes are based on key hash values
		- Only useful for equality conditions
			- Consecutive keys may be stored far apart
				- Similar hash values does not imply similar key values
		- Condition must constrain all components
			- Key with same prefix may be stored far apart
### Hash Index Variants
- Static hashing
	- Bad for dynamic data
	- Hash bucket pages contains references to data (or contain data directly)
	- Hash buckets are associated with hash value ranges
	- Can use hash index to find entries with key $V$
		- Calculate hash value $h$ for $V$ as $h(V)$
		- Look up bucket page associated with $h$
	- Updates
		- Deletion: Remove associated entries
		- Insertion: What if bucket is full?
			- Can add overflow pages
			- Initial bucket page stores pointer to first overflow page
			- Overflow pages form linked list if more than one
		- Can rehash if number of overflow pages increase
	- Pro: Can get data with one read
	- Cons
		- May need multiple reads in case of overflow pages
		- Will waste space if too many deletions (empty pages)
		- Can use rehashing but creates significant overheads
- Extendible hashing
	- Expands with few high-overhead operations
	- Idea: Use directory to map hash buckets to pages
		- More flexible than using page IDs directly
	- Redistribute overflowing buckets to multiple pages
		- More efficient than rehashing all data
	- Need to increase directory size if too many splits
	- Insertions
		- Calculate hash value for key of new entry
		- Consult directory to identify current bucket
		- Insert if current bucket has space
		- Otherwise, add new bucket page and rehash existing and new entry
			- For rehashing consider one more bit of hash value
			- Expand directory if it does not consider enough bits
	- Deletions
		- Can merge bucket pages if they become empty
		- Can half directory size if number of bucket shrinks
		- Often no compaction in practice; assume inserts are more common than deletes
	- Pros
		- Avoids overflow pages
		- No need for expensive rehashing
			- Only rehash one bucket at a time
	- Cons
		- Need additional directory access
		- Need to double directory occasionally, which may take up some time
- Linear hashing
	- Expands more smoothly
	- Idea: Avoid directory by fixing next bucket to split
		- We do not always split overflowing bucket
		- We may have temporary overflow pages
		- Buckets to split are selected in round robin fashion
		- Overflowing buckets will be split eventually
	- Calculate hash value for new entry to insert
	- Add entry on page or on overflow page if needed
	- Split next bucket if trigger condition is satisfied
		- May eliminate previously generated overflow pages
		- Some flexibility in choice of trigger condition
	- Splitting proceeds in rounds
		- All buckets present at round start split until round ends
		- Next split pointer is reset to first page at round end
	- We split the bucket pointed to by `Next Split`
		- Add one new page and redistribute split bucket entries
		- Consider one more bit when redistributing
	- Pros
		- Avoids a directory; no expensive directory doubling
	- Cons
		- May temporarily admit overflow pages
		- May split empty pages; inefficient space utilization
### Terminology
- Global depth: How many hash bits directory considers
- Local depth: How many hash bits for specific bucket
### Optimizations
- Can apply same optimizations as for tree indexes
- Have many entries for the same search key value
	- Store key value, followed by list of references
- Want to get rid of one level of indirection
	- Can store data directly instead of references
	- Leads to clustered index, only one per table
	- Clustered index: data sorted by index key
### Choose Index Type in Postgres
- `CREATE INDEX <index-name> ON <table> USING <method>(<column-list>)`
- Can choose `btree` or `hash` for method
