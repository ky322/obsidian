[[Devore 5.1]]

- Recall a random variable $X:S\rightarrow\mathbb{R}$ is a function that assigns the number $X(s)$ to each outcome $s\in S$
- We can define multiple random variables on the same sample space. For each outcome $s\in S$ assign the numbers $X_1(s), X_2(S),...$
- If we have n random variables defined on the sample space S the joint PMF $p(x_1,...,x_n)$ gives the probability of each possible tuple $(x_1,...x_n)$
### Joint PMF
- Let X and Y be random variables defined on the sample sample space S. The joint probability mass function of X and Y is $$p_{x,y}(x,y)=P(X=x,Y=y)$$
- For any joint PMF $$p_{x,y}(x,y)\geq 0, \sum_x\sum_yp_{x,y}(x,y)=1$$
- For any set A $$P((X,Y)\in A)=\sum_{(x,y)\in A}p_{x,y}(x,y)$$
### Marginal PMFs
- Given a joint pmf the marginal PMF are $$p_x(x)=\sum_yp_{x,y}(x,y), p_y(y)=\sum_xp_{x,y}(x,y)$$
### Expectation
- Given a real valued function $g(x,y)$ $$E(g(X,Y))=\sum_x\sum_yg(x,y)p_{x,y}(x,y)$$
### Conditional PMF
- Let X, Y be random variables with joint PMF $p_{x,y}(x,y)$. For any x where $p_x(x)>0$ the conditional PMF of Y given X=x is $$p_{y|x}(y|x)=P(Y=y|X=x)=\frac{p_{x,y}(x,y)}{p_x(x)}$$
### Independence
- Two events A and B are independent if $P(A\cap B)=P(A)P(B)$
- Random variables X and Y are independent if for any events A, B $$P(X\in A, Y\in B)=P(X\in A)P(Y\in B)$$ and $$p_{x,y}(x,y)=p_x(x)p_y(y)$$
### Simpson's Paradox
- If $$P(Y_1=1|X_1=x)>P(Y_2=1|X_2=x)$$ it is not necessary that $$P(Y_1=1)>P(Y_2=1)$$
