- Given data pairs $(x_1,y_1),\cdots,(x_n,y_n)$ x is an independent or predictor variable
	- Used to estimate the value y takes on 
	- Can be controlled by the experimenter
	- y is the dependent or response variable and can only be observed
- Attempt to fit the line $y=\beta_0+\beta_1x$ to the data
	- Error associated with the ith point $\epsilon_i=y_i-\beta_0-\beta_1x_i$
- The fit of a line to the data using sum of squared errors $$SSE(\beta_0,\beta_1)=\sum_{i=1}^n\epsilon_i^2=\sum_{i=1}^n(y_i-\beta_0-\beta_1x_i)^2$$
- The least squares line $\hat{\beta_0}+\hat{\beta_1}x$ is the line that minimizes the sum of squared errors $$\min_{\beta_0\beta_1} \sum_{i=1}^n(y_i-\beta_0-\beta_1x_i)^2$$
- Find $\hat{\beta_0}$ and $\hat{\beta_1}$ by 
![[Pasted image 20231203001803.png]]
### Optimal Coefficients
![[Pasted image 20231203001927.png]]
- To find the best line solve 
![[Pasted image 20231203002025.png]]
- $$R^2=1-\frac{SSE*}{SST}=1-\frac{SSE(\hat{\beta_0},\hat{\beta_1})}{SSE(\bar{y},0)}$$
- Closer to $1$ the better the fit
- Responses $Y_i$ and predictors $x_i$ satisfy an underlying linear relation muddled by random noise
	- Assume $Y_i=\beta_0+\beta_1x_i+\epsilon_i$ where the errors are iid $N(0,\sigma^2)$ random variables
	- $E(Y_i)= \beta_0+\beta_1x_i, Var(Y_i)=\sigma^2$
### Slope and Intercept Estimators
- $\hat{\beta_1}=\frac{\sum_{i=1}^n(x-\bar{x})(Y_i-\bar{Y_n})}{\sum_{i=1}^n(x-\bar{x})^2}$
- $\hat{\beta}_0=\bar{Y_n}-\hat{\beta_1}\bar{x}$
- ![[Pasted image 20231203002814.png]]
- ![[Pasted image 20231203002840.png]]
- ![[Pasted image 20231203002857.png]]
- ![[Pasted image 20231203002926.png]]
- ![[Pasted image 20231203002948.png]]
- ![[Pasted image 20231203003016.png]]
- ![[Pasted image 20231203003058.png]]
### Summary
- Regression is used to identify a linear relationship between the  response y and the predictor x.  
-  We choose the line that minimizes the sum of the vertical  distances between the points and the fitted line (the sum of  squared errors).  
-  Under a probabilistic model, the errors are assumed to be  independent, normally distributed, with constant variance.  
- We can test for β1 6 = 0, i.e., there is a linear relationship between the variables. Can also construct CI for β1.  
- We can obtain a CI for the mean response value, or a  prediction interval for the random response value, at a fixed x.