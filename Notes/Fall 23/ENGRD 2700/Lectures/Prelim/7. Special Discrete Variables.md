[[Devore 3.4, 3.5, 3.6]]
### Bernoulli R.V.’s
- Given $p\in[0,1]$ X is a Bernoulli random variable with parameter $p$ written $X\sim\text{Bern}(p)$ if its a set of possible values is $X=\{0,1\}$ and its PMF is $$p_x(x) = \begin{cases}1-p\text{ if x=0}\\ p\text{ if x=1}\end{cases}$$
- If $X\sim\text{Bern}(p)$
	- E(X) = p
	- Var(X) = p(1-p)
- Used to model random experiments/ phenomena with only two possible outcomes
- Bernoulli Trial: A random experiment or phenomena that has exactly two outcomes. 
	- Such experiment can be modeled by a Bernoulli r.v.
	- We are interested in a sequence of Bernoulli Trial
### Binomial R.V.’s
- Given $n\in\{1,2,\cdots\}$ and $p\in[0,1]$ X is a binomial random variables with parameter p, written $$X\sim B(n,p)$$ if its set of possible values is $X=\{0,1,\cdots,n\}$ and its PMF is $$p_X(x)=\binom{n}{x}p^x(1-p)^{n-x}, x=0,1,\cdots,n$$ *The binomial probabilities add up to 1
- If $X\sim B(n,p)$ 
	- E(X)=np
	- Var(X) = np(1-p)
- Used to model the number of successes in a sequence of n independent Bernoulli trials
### Poisson R.V.’s
- Given $\lambda>0$ X is a Poisson random variable with parameter $\lambda$ $$X\sim\text{Pois}(\lambda)$$ if its set of possible values is $X=\{0,1,\cdots\}$ and its PMF is $$p_X(x)=\frac{e^{-\lambda}\lambda^x}{x!}, x=0,1,2\cdots$$
- If $X\sim\text{Pois}(\lambda)$
	- $E(X)=\lambda$
	- $\text{Var}(X)=\lambda$
- Poisson R.V.’s can be used to model the number of times that an event occurs during a fixed length of time when
	1. The probability that an event occurs during a given interval is proportional to the length of that interval
	2. The occurrence of an event does not change the probability that another will occur
	3. Two events cannot occur at exactly the same time
#### Poisson’s Approximation
- Used to approximate $p_X(X)$ when $X\sim B(n,p)$
- Include latter too much latexing
### Geometric R.V.’s
- Given $p\in[0,1]$ X is a geometric random variable with parameter p written $$X\sim\text{Geom}(p)$$ if its set of possible values is $X=\{1,2,\cdots\}$ and its PMF is $$p_X(x)=(1-p)^{x-1}p,x=1,2,\cdots$$
- If $X\sim\text{Geom}(p)$
	- $E(X)=\frac{1}{p}$
	- $Var(X)=\frac{1-p}{p^2}$
- X is the number of independent Bernoulli trials needed to obtain the first success. A success occurs with probability p
### Hypergeometric R.V.’s
- Given $N\in\{1,2,\cdots\}$ and $N_s,n\in\{1,\cdots N\}$ X is a hypergeometric random variable with parameters N, $N_S$m n written $$X\sim\text{Hyp}(N, N_s,n)$$ if its set of possible values is $X=\{0,1,\cdots, N_s\}$ and its PMF is $$p_X(x)=\frac{\binom{N_s}{x}\binom{N-N_s}{n-x}}{\binom{N}{n}}, x=0,1,\cdots,N_s$$
- If $X\sim\text{Hyp(p)}$
	- $E(X)=n\frac{N_s}{N}$
	- $\text{Var(X)}=(\frac{N-n}{N-1})(n\cdot\frac{N_s}{N})(1-\frac{N_s}{N})$
- Hypergeometric r.v.’s can be used to model sampling without replacement
	- Number of successes when sampling without replacement
- If we let $p=\frac{N_s}{N}$
	- $E(X)=np$
	- $\text{Var}(X) = \frac{N-n}{N-1}np(1-p)$